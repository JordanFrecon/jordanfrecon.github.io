import{b as n,o as s,w as i,g as e,ae as t,v as u,x as c,X as l}from"./modules/vue-DQ9iuSIT.js";import{_ as m}from"./slidev/iframe-right.vue_vue_type_script_setup_true_lang-NaodLMPK.js";import{u as p,f as d}from"./slidev/context-DpLOu9mk.js";import"./index-DnAgST0G.js";import"./monaco/bundled-types-C8a_JgbF.js";import"./modules/file-saver-BzOOqXCn.js";import"./modules/shiki-Dxkq1cMF.js";const B={__name:"datascience_5-vectorize-dimension.md__slidev_16",setup(_){const{$clicksContext:r,$frontmatter:a}=p();return r.setup(),(f,o)=>(s(),n(m,u(c(l(d)(l(a),15))),{default:i(()=>o[0]||(o[0]=[e("h1",null,"Bag of Words Vectorization",-1),e("p",null,[t("What "),e("mark",null,"CountVectorizer"),t(" does:")],-1),e("ul",null,[e("li",null,"Tokenizes text (with optional preprocessing)"),e("li",null,"Builds a vocabulary (dictionary) of all tokens"),e("li",null,[t("Creates a "),e("strong",null,"sparse"),t(" matrix where "),e("ul",null,[e("li",null,"each row = document"),e("li",null,"each column = token"),e("li",null,"each entry = token counts")])])],-1)])),_:1},16))}};export{B as default};
