import{b as n,o as s,w as i,g as e,ae as t,v as u,x as c,X as l}from"./modules/vue-rYqNAK_y.js";import{_ as m}from"./slidev/iframe-right.vue_vue_type_script_setup_true_lang-Bu9NPnmC.js";import{u as p,f as d}from"./slidev/context-DUJiwf6J.js";import"./index-C39ZsbL1.js";import"./monaco/bundled-types-D6QPnxzs.js";import"./modules/file-saver-BzOOqXCn.js";import"./modules/shiki-BwYsuT2u.js";const B={__name:"5-datascience-vectorize-dimension.md__slidev_15",setup(f){const{$clicksContext:r,$frontmatter:a}=p();return r.setup(),(_,o)=>(s(),n(m,u(c(l(d)(l(a),14))),{default:i(()=>o[0]||(o[0]=[e("h1",null,"Bag of Words Vectorization",-1),e("p",null,[t("What "),e("mark",null,"CountVectorizer"),t(" does:")],-1),e("ul",null,[e("li",null,"Tokenizes text (with optional preprocessing)"),e("li",null,"Builds a vocabulary (dictionary) of all tokens"),e("li",null,[t("Creates a "),e("strong",null,"sparse"),t(" matrix where "),e("ul",null,[e("li",null,"each row = document"),e("li",null,"each column = token"),e("li",null,"each entry = token counts")])])],-1)])),_:1},16))}};export{B as default};
