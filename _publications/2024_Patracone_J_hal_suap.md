---
layout: publication
title: A Theoretically Grounded Extension of Universal Attacks from the Attacker's Viewpoint
authors: J. Frecon, P. Viallard, E. Morvant, G. Gasso, A. Habrard and S. Canu
publication: Under review
year: 2024
doi:
image: False
type: unpublished
project: adversarialLearning
---


We extend universal attacks by jointly learning a set of perturbations to choose from to maximize the chance of attacking deep neural network models. Specifically, we embrace the attacker's perspective and introduce a theoretical bound quantifying how much the universal perturbations are able to fool a given model on unseen examples. An extension to assert the transferability of universal attacks is also provided. To learn such perturbations, we devise an algorithmic solution with convergence guarantees under Lipschitz continuity assumptions. Moreover, we demonstrate how it can improve the performance of state-of-the-art gradient-based universal perturbation. As evidenced by our experiments, these novel universal perturbations result in more interpretable, diverse, and transferable attacks.
